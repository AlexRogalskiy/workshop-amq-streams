== Security for clusters and topics

=== Securing listeners

The first step for securing a Kafka cluster is securing its listeners.
You can add security options to each of the configured listeners.
For example, let us change the cluster definition:

----
cat >> production-ready-secured.yaml <<'EOF'
apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: production-ready
spec:
  kafka:
    replicas: 3
    listeners:
      plain:
        authentication:
          type: scram-sha-512
      tls: {}
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
    storage:
      type: persistent-claim
      size: 20Gi
      deleteClaim: false
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 1Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
EOF
----

Let's deploy the new configuration:

----
oc apply -f production-ready-secured.yaml
----

The `plain` listener is now configured to use the `SCRAM` challenge mechanism for connecting clients.

=== Creating users and ACLs

Now that we have configured the broker to be secured, we need to create users so that our clients can connect.
Users are managed through `KafkaUser` resources, which also manage the user authorization.
Let's create our first user.

----
cat >> secured-topic-reader.yaml <<'EOF'
apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: secure-topic-reader
  labels:
    strimzi.io/cluster: production-ready
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      # Example consumer Acls for topic secureTopic using consumer group
      - resource:
          type: topic
          name: secure-topic
          patternType: literal
        operation: Read
        host: "*"
      - resource:
          type: topic
          name: secure-topic
          patternType: literal
        operation: Describe
        host: "*"
      - resource:
          type: group
          name: secure-group
          patternType: literal
        operation: Read
        host: "*"
EOF
----

Let's apply this new configuration.

----
oc apply -f test-topic-reader-user.yaml
----

The newly created user can read the metadata of topic `test-topic` and consume (read) from it with the consumer group `test-group`.

But now we need a user that can produce data to `test-topic`!
Let's create a new resource:
----
cat >> secure-topic-writer.yaml <<'EOF'
apiVersion: kafka.strimzi.io/v1alpha1
kind: KafkaUser
metadata:
  name: test-topic-writer
  labels:
    strimzi.io/cluster: production-ready
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls:
      # Example Producer Acls for topic my-topic
      - resource:
          type: topic
          name: streams-plaintext-input
          patternType: literal
        operation: Write
        host: "*"
EOF
----

And let's apply this new configuration.
----
oc apply -f test-topic-reader-user.yaml
----

Go to `Secrets` and observe that new secret named `test-topic-reader` and `test-topic-writer` have been created.
This secret has a field named `password`.
This is the password to be used by the user.

Now let's redeploy our running applications.
Looking at the logs, we see a lot of errors - the clients cannot connect anymore.

We need to reconfigure the running apps:


----
cat >> timer-producer-app.yaml <<'EOF'
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: timer-producer
  labels:
    app: kafka-workshop
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: kafka-workshop
        name: timer-producer
    spec:
      containers:
        - name: timer-producer
          image: docker.io/mbogoevici/timer-producer:latest
          env:
            - name: CAMEL_COMPONENT_KAFKA_CONFIGURATION_BROKERS
              value: "production-ready-kafka-bootstrap.amq-streams.svc:9092"
EOF
----

----
oc apply -f timer-producer-app.yaml
----

----
cat >> log-consumer-app.yaml <<'EOF'
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: log-consumer
  labels:
    app: kafka-workshop
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: kafka-workshop
        name: log-consumer
    spec:
      containers:
        - name: log-consumer
          image: docker.io/mbogoevici/log-consumer:latest
          env:
            - name: CAMEL_COMPONENT_KAFKA_CONFIGURATION_BROKERS
              value: "production-ready-kafka-bootstrap.amq-streams.svc:9092"
            - name: CAMEL_COMPONENT_KAFKA_CONFIGURATION_GROUP_ID
              value: testGroup
            - name: CAMEL_COMPONENT_KAFKA_CONFIGURATION_SASL_JAAS_CONFIG
              value: org.apache.kafka.common.security.scram.ScramLoginModule required username=${KAFKA_USER} password=${KAFKA_PASSWORD}
            - name: CAMEL_COMPONENT_KAFKA_CONFIGURATION_SASL_MECHANISM
              value: SCRAM-SHA-512
            - name: CAMEL_COMPONENT_KAFKA_CONFIGURATION_SECURITY_PROTOCOL
              value: SASL_PLAINTEXT
            - name: KAFKA_USER
              value: test-topic-reader
            - name: KAFKA_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: password
                  name: test-topic-reader
----


----
camel.component.kafka.configuration.brokers=my-cluster-kafka-bootstrap.amq-streams.svc:9092
camel.component.kafka.configuration.group-id=testGroup
camel.component.kafka.configuration.sasl-jaas-config=;
camel.component.kafka.configuration.sasl-mechanism=SCRAM-SHA-512
camel.component.kafka.configuration.security-protocol=SASL_PLAINTEXT
----

Where do the values for `$KAFKA_USER` and `$KAFKA_PASSWORD` come from?
They need to be injected into the configuration from the deployment.

Let's add the two propertie to the deployment:

----
- name: KAFKA_USER
  value: test-topic-reader
- name: KAFKA_PASSWORD
  valueFrom:
    secretKeyRef:
      key: password
      name: test-topic-reader
----

and

----
- name: KAFKA_USER
  value: test-topic-writer
- name: KAFKA_PASSWORD
  valueFrom:
    secretKeyRef:
      key: password
      name: test-topic-writer
----
