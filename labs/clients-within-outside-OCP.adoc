== Connecting from outside OCP

As you have seen, a Kafka cluster deployed in OpenShift can be used by other applications deployed in the same OpenShift instance.
This is the primary use case.

=== Configuring external routes

In certain scenarios, a Kafka cluster deployed in OpenShift may need to be accessed from outside the cluster.
Let's see how that can be enabled.

First, we need to reconfigure the cluster with an `external` listener.

----
apiVersion: kafka.strimzi.io/v1alpha1
kind: Kafka
metadata:
  name: production-ready
spec:
  kafka:
    replicas: 3
    listeners:
      plain: {}
      tls: {}
      external:
        type: route
    config:
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
    storage:
      type: persistent-claim
      size: 3Gi
      deleteClaim: false
  zookeeper:
    replicas: 3
    storage:
      type: persistent-claim
      size: 1Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}
----

Now let's apply this configuration to the running cluster.

----
oc apply -f https://raw.githubusercontent.com/mbogoevici/workshop-amq-streams/master/configurations/clusters/production-ready-external-routes.yaml
----

Now you can inspect the existing services.
Notice that each of the brokers in the cluster has a route and a new bootstrap service has been created for external connections.

=== Connecting external clients

For interacting with the broker, external clients must use TLS.
First, we need to extract the certificate of the server.
----
oc extract secret/production-ready-cluster-ca-cert --keys=ca.crt --to=- >certificate.crt
----

Then, we need to install it into a Java keystore.

----
keytool -import -trustcacerts -alias root -file certificate.crt -keystore keystore.jks -storepass password -noprompt
----

We can now run our producer and consumer applications by using this certificate.
